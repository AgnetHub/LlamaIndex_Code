{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingfaceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl.metadata (767 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (0.12.16.post1)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.10)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.5)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\code\\llamaindex_code-main\\llamaindex_venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/204.1 MB 11.4 MB/s eta 0:00:18\n",
      "    --------------------------------------- 4.7/204.1 MB 11.9 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 7.3/204.1 MB 12.1 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 10.0/204.1 MB 12.2 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 12.6/204.1 MB 12.1 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 15.2/204.1 MB 12.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 17.8/204.1 MB 12.2 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 20.4/204.1 MB 12.2 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 22.8/204.1 MB 12.1 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 25.2/204.1 MB 11.9 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 27.3/204.1 MB 11.9 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 28.0/204.1 MB 11.1 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 30.7/204.1 MB 11.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 33.3/204.1 MB 11.3 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 35.7/204.1 MB 11.3 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 38.0/204.1 MB 11.3 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 40.6/204.1 MB 11.3 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 43.0/204.1 MB 11.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 45.6/204.1 MB 11.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 48.2/204.1 MB 11.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 50.9/204.1 MB 11.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 53.5/204.1 MB 11.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 56.1/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 58.7/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 61.1/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 63.7/204.1 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 66.1/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 68.4/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 70.8/204.1 MB 11.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 73.1/204.1 MB 11.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 75.5/204.1 MB 11.5 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 78.1/204.1 MB 11.5 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 80.5/204.1 MB 11.6 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 83.1/204.1 MB 11.6 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 85.7/204.1 MB 11.6 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 88.3/204.1 MB 11.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 91.0/204.1 MB 11.6 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 93.3/204.1 MB 11.6 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 95.9/204.1 MB 11.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 98.6/204.1 MB 11.7 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 101.2/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 103.5/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 106.2/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 108.5/204.1 MB 11.7 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 110.9/204.1 MB 11.6 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 113.2/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 115.9/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 118.5/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 120.8/204.1 MB 11.7 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 123.5/204.1 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 126.1/204.1 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 128.7/204.1 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 131.1/204.1 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 133.7/204.1 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 136.1/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 138.7/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 141.3/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 143.9/204.1 MB 11.7 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 146.5/204.1 MB 11.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 149.2/204.1 MB 11.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 151.8/204.1 MB 11.8 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 154.1/204.1 MB 11.8 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 156.8/204.1 MB 11.8 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 159.1/204.1 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 161.7/204.1 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 164.1/204.1 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 166.5/204.1 MB 11.8 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 169.1/204.1 MB 11.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 171.2/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 173.8/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 176.4/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 178.8/204.1 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 181.4/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.8/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.4/204.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 189.0/204.1 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.4/204.1 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 194.0/204.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.6/204.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.0/204.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.6/204.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.1/6.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.1 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/41.0 MB 12.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/41.0 MB 11.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.1/41.0 MB 11.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.7/41.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.3/41.0 MB 11.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.7/41.0 MB 11.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.3/41.0 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 19.1/41.0 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.8/41.0 MB 11.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.4/41.0 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.7/41.0 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.4/41.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/41.0 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.3/41.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/41.0 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.1/41.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: threadpoolctl, sympy, setuptools, scipy, safetensors, torch, scikit-learn, transformers, sentence-transformers, llama-index-embeddings-huggingface\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed llama-index-embeddings-huggingface-0.5.1 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 setuptools-75.8.0 sympy-1.13.1 threadpoolctl-3.5.0 torch-2.6.0 transformers-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\LlamaIndex_Code-main\\LlamaIndex_VENV\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# 환경 변수 설정\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama LLM 설정\n",
    "llm = Ollama(\n",
    "    model=\"deepseek-r1:8b\",  # Ollama에서 제공하는 deepseek-r1:8b 모델 사용\n",
    "    temperature=0.1,  # 응답의 창의성 조절 (0에 가까울수록 일관된 응답)\n",
    "    context_window=4096,  # 컨텍스트 윈도우 크기\n",
    "    timeout=120,  # 타임아웃 시간을 120초로 설정\n",
    "    request_timeout=120,  # 요청 타임아웃도 120초로 설정\n",
    "    additional_kwargs={  # 추가 파라미터\n",
    "        \"num_gpu\": 0,  # CPU 사용 설정\n",
    "        \"seed\": 42,  # 재현성을 위한 시드 설정\n",
    "    },\n",
    ")\n",
    "\n",
    "# BGE 임베딩 모델 설정\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-m3\", device=\"cpu\"  # CPU 사용. GPU의 경우 \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ServiceContext 설정\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# PDF 문서 로드\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"../data/pdf_sample1/240828_(AI리포트)_미국의_인공지능(AI)_정책,전략.pdf\"],\n",
    "    filename_as_id=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 생성\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# 쿼리 엔진 생성\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True,  # 스트리밍 응답 활성화\n",
    "    similarity_top_k=3,  # 상위 3개의 가장 관련성 높은 문서 청크 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to figure out who the person is that mentioned the important role of the AI Safety Research Institute in establishing U.S. leadership in responsible AI development and with whom they are collaborating.\n",
      "\n",
      "First, looking at the context provided, there's a mention of OpenAI's Chief Security Officer (CSO) saying that the AI Safety Research Institute plays an important role in making the U.S. leadership clear in responsible AI development. So, the person in question is likely this CSO from OpenAI.\n",
      "\n",
      "Next, I need to determine who they are collaborating with. The context mentions that OpenAI, Anthropic, and Microsoft have joined forces with the U.S. AI Safety Research Institute (USAISI) for rigorous testing before deploying AI models widely. So, the collaborations involve these companies working alongside USAISI.\n",
      "\n",
      "Putting it together, the person is the CSO from OpenAI, and they are collaborating with OpenAI, Anthropic, Microsoft, and USAISI.\n",
      "</think>\n",
      "\n",
      "The individual in question is the Chief Security Officer (CSO) of OpenAI, who has highlighted the role of the AI Safety Research Institute (USAISI) in establishing U.S. leadership in responsible AI development. This CSO collaborates with OpenAI, Anthropic, Microsoft, and USAISI to ensure rigorous testing and safe deployment of AI models.\n",
      "\n",
      "**Answer:**  \n",
      "The person is the Chief Security Officer of OpenAI, who collaborates with OpenAI, Anthropic, Microsoft, and the U.S. AI Safety Research Institute (USAISI).\n"
     ]
    }
   ],
   "source": [
    "# 질문하기\n",
    "response = query_engine.query(\n",
    "    \"\"\"\n",
    "    책임 있는 AI 개발에서 미국의 리더십을 명확히 하는 데에\n",
    "    AI안전 연구소가 맡은 중요한 역할이 있다고 생각한다고 말한 사람과 \n",
    "    그 사람이 누구와 협력한다고 했는지 알려줘\n",
    "    \"\"\"\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
