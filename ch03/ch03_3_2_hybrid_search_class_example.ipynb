{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "class HybridSearch():\n",
    "    def __init__(self, bm25_retriever, semantic_retriever,\n",
    "                 bm25_weight=0.5, semantic_weight=0.5):\n",
    "        self.bm25_retriever = bm25_retriever # bm25 검색기 객체\n",
    "        self.semantic_retriever = semantic_retriever # 밀집 검색 객체\n",
    "        self.bm25_weight = bm25_weight # bm25 가중치\n",
    "        self.semantic_weight = semantic_weight # 밀집 검색 가중치\n",
    "\n",
    "    def _get_bm25_retrieve(self, query:str)->list:\n",
    "        result = self.bm25_retriever.retrieve(query)\n",
    "        # (node 객체, 가중치 반영 점수)의 튜플 리스트로 반환\n",
    "        score = [(node.node, node.score * self.bm25_weight) for node in result]\n",
    "        return score\n",
    "\n",
    "    def _get_semantic_retrieve(self, query:str)->list:\n",
    "        result = self.semantic_retriever.retrieve(query)\n",
    "        # (node 객체, 가중치 반영 점수)의 튜플 리스트로 반환\n",
    "        score = [(node.node, node.score * self.semantic_weight) for node in result]\n",
    "        return score\n",
    "\n",
    "    # 혼합 검색 node 반환\n",
    "    def retrieve(self, query:str)->list[NodeWithScore]:\n",
    "        bm25_result = self._get_bm25_retrieve(query=query)\n",
    "        semantic_result = self._get_semantic_retrieve(query=query)\n",
    "        \n",
    "        # key: node 객체, value: 최종 점수\n",
    "        combined_scores = {}\n",
    "\n",
    "        # BM25 점수 반영\n",
    "        for node, score in bm25_result:\n",
    "            combined_scores[node.text] = {'node':node, 'score':score}\n",
    "        \n",
    "        # Semantic 점수 반영\n",
    "        for node, score in semantic_result:\n",
    "            if node.text in combined_scores: # 이미 존재하는 청크인 경우\n",
    "                print('확인')\n",
    "                combined_scores[node.text]['score'] += score\n",
    "            else: # 새로운 청크인 경우\n",
    "                \n",
    "                combined_scores[node.text] = {'node':node, 'score':score}\n",
    "        \n",
    "        # NodeWithScore 형태 리스트로 변환\n",
    "        final_results = []\n",
    "        for _, node_info in combined_scores.items():\n",
    "            if node_info['score'] == 0: continue # 점수가 0점인 경우 제외\n",
    "            final_results.append(NodeWithScore(node=node_info['node'], score=node_info['score']))\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step1. 문서 준비\n",
    "sample_documents = [\n",
    "    \"RAG 기술의 최신 동향\",\n",
    "    \"최신 검색 증강 시스템 연구\",\n",
    "    \"RAG을 활용한 챗봇 개발\",\n",
    "    \"RAG와 Dense Passage Retrieval의 비교 연구\",\n",
    "    \"최신 AI 논문: 검색 증강 기술\",\n",
    "]\n",
    "\n",
    "### Document 객체 생성\n",
    "from llama_index.core import Document\n",
    "documents = [Document(text=doc) for doc in sample_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step2. 희소 검색을 위한 형태소 분석기 함수 작성\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt() # Okt 형태소 분석기 초기화\n",
    "def tokenize_korean_text(text): # 문서 내용 토큰화 함수 정의\n",
    "    return okt.morphs(text)  # 한국어 형태소 기반 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step3.  LLM 및 Embedding Model 설정\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\", temperature=0.5)  # 모델명은 예시\n",
    "embedding_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step4. 청킹을 위한 Splitter 설정\n",
    "# 청킹 (chunking)\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 저장 된 인덱스 불러오기\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "storage_context1 = StorageContext.from_defaults(persist_dir=\"./index/ch03_3_2_keyword_index_storage\") \n",
    "storage_context2 = StorageContext.from_defaults(persist_dir=\"./index/ch03_3_2_vector_index_storage\") \n",
    "keyword_index = load_index_from_storage(storage_context1) # BM25 검색 인덱스 로드\n",
    "vector_index = load_index_from_storage(storage_context2) # 밀집 검색 인덱스 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bm25 retriever 객체 생성(keyword_index 연결)\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    index=keyword_index,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "\n",
    "# dense retriever 객체 생성(vector_index 연결)\n",
    "semantic_retriever = vector_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확인\n",
      "확인\n",
      "확인\n",
      "확인\n",
      "확인\n"
     ]
    }
   ],
   "source": [
    "query='검색 증강 생성'\n",
    "# 혼합 검색 클래스 객체 생성\n",
    "hybrid = HybridSearch(bm25_retriever=bm25_retriever,\n",
    "                      semantic_retriever=semantic_retriever)\n",
    "combined_score = hybrid.retrieve(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 83b9502f-4a46-4ec4-b062-443a38350cb6\n",
      "Text: 최신 검색 증강 시스템 연구\n",
      "Score:  0.802\n",
      "\n",
      "Node ID: 3f0f7daf-356e-4127-9e3c-69e1a318bbbf\n",
      "Text: 최신 AI 논문: 검색 증강 기술\n",
      "Score:  0.759\n",
      "\n",
      "Node ID: f6b58938-84cd-4891-b4c7-401727cf2e19\n",
      "Text: RAG와 Dense Passage Retrieval의 비교 연구\n",
      "Score:  0.396\n",
      "\n",
      "Node ID: 50dc4e3c-a1b4-4162-9f15-af11a4039af2\n",
      "Text: RAG을 활용한 챗봇 개발\n",
      "Score:  0.410\n",
      "\n",
      "Node ID: ad6fbdd9-7ba0-4f8f-8276-e6c0cdb1e43c\n",
      "Text: RAG 기술의 최신 동향\n",
      "Score:  0.403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rufrhk 결과 출력\n",
    "for node_score_obj in combined_score:\n",
    "    print(node_score_obj)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
