{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 Cross-encoder 기반의 RAG 시스템 구현\n",
    "(코드 재확인 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sentence_transformers\n",
    "! pip install chromadb\n",
    "! pip install llama_index.vector_stores.chroma\n",
    "! pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cross Encoder 기반 reranker 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\OneDrive\\Desktop\\Project\\llamaindex_practice\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step1. 크로스 인코더를 이용한 Reranker 클래스\n",
    "from sentence_transformers import CrossEncoder\n",
    "from llama_index.core import Document # 임의의 Document 객체를 만들기 위한 클래스 import\n",
    "from llama_index.core.schema import NodeWithScore, TextNode\n",
    "\n",
    "class CrossEncoderReranker:\n",
    "    # 초기화 메서드\n",
    "    def __init__(self, top_k:int = 2, cross_encoder:CrossEncoder=None,threshold:float=0.0):\n",
    "        self.top_k = top_k # 관련성 점수 상위 k개 문서 반환\n",
    "        self.cross_encoder = cross_encoder # 크로스 인코더 모델\n",
    "        self.threshold = threshold # 관련성 점수 기준값\n",
    "    \n",
    "    # query와 문장을 pair로 입력받아 sorting\n",
    "    def rerank(self, query:str, documents:list[Document]):\n",
    "        # cross encoder 사용을 위한 쿼리&문서 pair 만들기\n",
    "        pairs = [[query, doc.text] for doc in documents]\n",
    "        # cross encoder rerank 수행\n",
    "        scores = self.cross_encoder.predict(pairs)\n",
    "        # score 기준 내림차순 정렬\n",
    "        scored_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "        # score 상위 k개 반환\n",
    "        scored_docs = scored_docs[:self.top_k]\n",
    "        final_docs = []\n",
    "        for doc, score in scored_docs:\n",
    "            if score > self.threshold: # 기준값이 넘는 경우에만\n",
    "                final_docs.append((doc,score))\n",
    "        return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 문서 리스트\n",
    "documents = [\n",
    "    Document(text=\"인공지능의 발전과 미래 전망에 대한 연구\"),\n",
    "    Document(text=\"머신러닝 알고리즘의 성능 평가 방법론\"),\n",
    "    Document(text=\"딥러닝 모델의 학습 최적화 기법\"),\n",
    "    Document(text=\"교육 분야에서 인공지능의 활용 방안 연구\"),\n",
    "    Document(text=\"검색 증강 생성 시스템 연구 동향\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"./reranker_model/bge-reranker-v2-m3\"\n",
    "cross_encoder = CrossEncoder(path) # 크로스 인코더 객체 생성\n",
    "\n",
    "query = \"인공지능의 미래는 어떨까요?\"\n",
    "reranker = CrossEncoderReranker(cross_encoder=cross_encoder) # 크로스 인코더 리랭커 객체 생성\n",
    "reranked_docs = reranker.rerank(query=query, documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 인공지능의 발전과 미래 전망에 대한 연구, score : 0.9195771217346191\n",
      "2. 교육 분야에서 인공지능의 활용 방안 연구, score : 2.619951010274235e-05\n"
     ]
    }
   ],
   "source": [
    "# 관련성 점수 상위 n개 순서대로 출력\n",
    "for idx, (node, score) in enumerate(reranked_docs, start=1):\n",
    "    print(f\"{idx}. {node.text}, score : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 필요한 문서 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step4. 데이터 로드\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader('./data').load_data()\n",
    "# print(f'문서의 총 개수 : {len(documents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hybrid Search 구현(Embedding+BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "class HybridSearch():\n",
    "    def __init__(self, bm25_retriever, semantic_retriever,\n",
    "                 bm25_weight=0.5, semantic_weight=0.5):\n",
    "        self.bm25_retriever = bm25_retriever # bm25 검색기 객체\n",
    "        self.semantic_retriever = semantic_retriever # 밀집 검색 객체\n",
    "        self.bm25_weight = bm25_weight # bm25 가중치\n",
    "        self.semantic_weight = semantic_weight # 밀집 검색 가중치\n",
    "\n",
    "    def _get_bm25_retrieve(self, query:str)->list:\n",
    "        result = self.bm25_retriever.retrieve(query)\n",
    "        # (node 객체, 가중치 반영 점수)의 튜플 리스트로 반환\n",
    "        score = [(node.node, node.score * self.bm25_weight) for node in result]\n",
    "        return score\n",
    "\n",
    "    def _get_semantic_retrieve(self, query:str)->list:\n",
    "        result = self.semantic_retriever.retrieve(query)\n",
    "        # (node 객체, 가중치 반영 점수)의 튜플 리스트로 반환\n",
    "        score = [(node.node, node.score * self.semantic_weight) for node in result]\n",
    "        return score\n",
    "\n",
    "    # 혼합 검색 node 반환\n",
    "    def retrieve(self, query:str)->list[NodeWithScore]:\n",
    "        bm25_result = self._get_bm25_retrieve(query=query)\n",
    "        semantic_result = self._get_semantic_retrieve(query=query)\n",
    "        \n",
    "        # key: node 객체, value: 최종 점수\n",
    "        combined_scores = {}\n",
    "\n",
    "        # BM25 점수 반영\n",
    "        for node, score in bm25_result:\n",
    "            combined_scores[node.text] = {'node':node, 'score':score}\n",
    "        \n",
    "        # Semantic 점수 반영\n",
    "        for node, score in semantic_result:\n",
    "            if node.text in combined_scores: # 이미 존재하는 청크인 경우\n",
    "                \n",
    "                combined_scores[node.text]['score'] += score\n",
    "            else: # 새로운 청크인 경우\n",
    "                combined_scores[node.text] = {'node':node, 'score':score}\n",
    "        \n",
    "        # NodeWithScore 형태 리스트로 변환\n",
    "        final_results = []\n",
    "        for _, node_info in combined_scores.items():\n",
    "            if node_info['score'] == 0: continue # 점수가 0점인 경우 제외\n",
    "            final_results.append(NodeWithScore(node=node_info['node'], score=node_info['score']))\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 혼합 검색 사용을 위한 각 검색기 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from konlpy) (1.5.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from konlpy) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from konlpy) (1.24.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-retrievers-bm25\n",
      "  Downloading llama_index_retrievers_bm25-0.5.2-py3-none-any.whl.metadata (740 bytes)\n",
      "Collecting bm25s<0.3.0,>=0.2.0 (from llama-index-retrievers-bm25)\n",
      "  Downloading bm25s-0.2.10-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-retrievers-bm25) (0.12.19)\n",
      "Collecting pystemmer<3.0.0.0,>=2.2.0.1 (from llama-index-retrievers-bm25)\n",
      "  Downloading PyStemmer-2.2.0.3-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.24.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\onedrive\\desktop\\project\\llamaindex_practice\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.1)\n",
      "Downloading llama_index_retrievers_bm25-0.5.2-py3-none-any.whl (3.7 kB)\n",
      "Downloading bm25s-0.2.10-py3-none-any.whl (53 kB)\n",
      "Downloading PyStemmer-2.2.0.3-cp310-cp310-win_amd64.whl (184 kB)\n",
      "Installing collected packages: pystemmer, bm25s, llama-index-retrievers-bm25\n",
      "Successfully installed bm25s-0.2.10 llama-index-retrievers-bm25-0.5.2 pystemmer-2.2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install konlpy\n",
    "%pip install llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Step4-1. LLM 및 Embedding Model 설정\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\", temperature=0.5)  # 모델명은 예시\n",
    "embedding_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Step4-2 희소 검색을 위한 형태소 분석기 함수 작성\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt() # Okt 형태소 분석기 초기화\n",
    "def tokenize_korean_text(text): # 문서 내용 토큰화 함수 정의\n",
    "    return okt.morphs(text)  # 한국어 형태소 기반 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step4-3. text splitter 설정\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step4-4. Keyword( BM25 ) Index 생성\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.indices.keyword_table import KeywordTableIndex\n",
    "keyword_index = KeywordTableIndex.from_documents(\n",
    "    documents=documents,\n",
    "    text_splitter=splitter,\n",
    "    extract_keyword=tokenize_korean_text,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# keyword index 생성\n",
    "keyword_index.storage_context.persist(persist_dir=\"./index/ch03_keyword_index_storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Step4-3 임베딩 모델을 사용 한  VectorStoreIndex 생성\n",
    "from llama_index.core import VectorStoreIndex\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    text_splitter=splitter,\n",
    "    embed_model=embedding_model,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "vector_index.storage_context.persist(persist_dir=\"./index/ch03_vector_index_storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 저장 된 인덱스 불러오기\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "storage_context1 = StorageContext.from_defaults(persist_dir=\"./index/ch03_keyword_index_storage\") \n",
    "storage_context2 = StorageContext.from_defaults(persist_dir=\"./index/ch03_vector_index_storage\") \n",
    "keyword_index = load_index_from_storage(storage_context1) # BM25 검색 인덱스 로드\n",
    "vector_index = load_index_from_storage(storage_context2) # 밀집 검색 인덱스 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    }
   ],
   "source": [
    "## bm25 retriever 객체 생성(keyword_index 연결)\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    index=keyword_index,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "\n",
    "# dense retriever 객체 생성(vector_index 연결)\n",
    "semantic_retriever = vector_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='가계부실위험지수에 대해 알고 싶어요.'\n",
    "# 혼합 검색 클래스 객체 생성\n",
    "hybrid = HybridSearch(bm25_retriever=bm25_retriever,\n",
    "                      semantic_retriever=semantic_retriever)\n",
    "combined_score = hybrid.retrieve(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 5eacbc34-1c8e-47ea-9bf5-edd57e036221\n",
      "Text: 무역금융지원  프로그램은 수출금융 지원을 위해 무역금융 취급실적에 대해 지원한다. 영세자영업자지 원 프로그램은\n",
      "영세자영업자 전환대출실적에 대해 지원한다. 지방중소기업지원 프로그 램은 지역 경제사정 등에 부합하는 지방중소기업 대상 대출에\n",
      "대해 지원한다. 중소기업 대출안정화 프로그램은 중소기업 신용의 변동성 완화 등을 위해 필요시 운영한다. 또한,  신규지원이\n",
      "종료된 설비투자지원 프로그램 잔액에 대해서도 지원한다. 지원조건을 보면,  대출금리는 프로그램별로 연 0.50~0.75%이다.\n",
      "대출기간은 1개월이며, 월중 취급실적  변동을 반영하기 위해 월단위로 갱신한다. 대출금액은 은행별 취급실적에 비례한다 .\n",
      "지원방식을 ...\n",
      "Score:  1.066\n",
      "\n",
      "Node ID: f6c23cea-ba7b-4bd1-b77b-e9f65c4e2cf9\n",
      "Text: 63 ㄱ  금융제도 금융거래에 관한 체계와 규범을 총칭하는 개념으로 금융시장, 금융기관, 금융기반구조 (infra-\n",
      "structure)로 구분된다. 금융시장은 자금의 수요자와 공급자간에 금융거래가 조직 적으로 이루어지는 장소로서 정보시스템 등\n",
      "추상적 공간을 포함하는 개념이다. 금융시장 은 은행 등 금융중개기관을 통하여 예금, 대출 등의 형태로 자금이전이 이루어지는\n",
      "간접금융시장과 주식, 채권 등 증권을 통해 자금의 수요자와 공급자간에 직접적인 자금이 전이 이루어지는 직접금융시장으로\n",
      "구분된다. 금융기관은 자금의 공급자와 수요자간에  거래를 성립시켜 주는 것을 목적으로 하는 사업체로서 우리나라의 경우 은행,\n",
      "비은행  예...\n",
      "Score:  1.011\n",
      "\n",
      "Node ID: 590e8c48-6968-48e4-bde1-d2e2caee0d10\n",
      "Text: 이는 특히 은행･보험･수출금융 등 금융업무절차나 자금세탁방지 (AML; Anti-Money Laundering)\n",
      "규제에서 자주 거론된다. 이 절차의 목적은 주로 은행이  자금세탁행위 등의 범죄 요소로 악용되는 것을 예방하는 것이다. 은행은\n",
      "고객과의 금융 거래를 더 잘 이해함으로써 고객의 리스크를 더 건전하게 관리할 수 있다 .   연관검색어 : 가상통화, 비트코인\n",
      "고용률 고용률은 통계청에서 매월 작성하고 있는 경제활동인구조사에서 집계된 15세 이상  인구(노동가능인구)에 대해 취업자가\n",
      "차지하는 비율을 말한다. 한편 실업률은 경제활동 인구 중에서 실업자가 차지하는 비율을 말한다. 고용률은 실업률의 문제점을\n",
      "해소할\n",
      "Score:  0.746\n",
      "\n",
      "Node ID: b0a0d57b-bffe-49ff-be83-6934538baf7d\n",
      "Text: 이러한 부작용을 완화하기 위한 제도의 하나가 가변예치의 무제도이다. 동 제도는 외국으로부터 유입된 자금에 대해 일정\n",
      "비율의 예치의무를 부과 함으로써 국경간 자본 유출입의 규모와 속도를 조절하는 수단이다. 우리나라는 외국환거 래법에서 국제수지\n",
      "및 국제금융 상 심각한 어려움에 처하는 경우와 통화정책･환율정책  및 기타 거시경제정책에 심각한 지장을 초래하는 경우에는\n",
      "기획재정부장관이 해당 자본 거래와 관련하여 취득하는 지급수단의 일부를 한국은행･외국환평형기금 또는 금융회사  등에 예치하도록\n",
      "하는 의무를 부과할 수 있다고 규정하고 있다. 다만, 이러한 조치는  특별한 사유가 없는 한 6개월 범위 내에서만 행할 수\n",
      "있고 그 ...\n",
      "Score:  0.704\n",
      "\n",
      "Node ID: dc3ad08a-3119-4603-ab42-ad17da51e584\n",
      "Text: 47 ㄱ  유가가 대표성을 상실하고 있다는 평가도 일부에서 제기되고 있다. 국제원유가격은  장기적으로 공급과 수요에\n",
      "의해 결정되나 원유공급지의 지정학적 리스크와 기상, 미달러  가치, 주요국 석유재고의 변동 등 많은 요인의 영향을 받는다 .\n",
      "연관검색어 : 선물거래 국제통화기금(IMF) 국제통화 및 금융제도의 안정을 도모하기 위한 국제금융기구로서 미국 워싱턴에\n",
      "본부를 두고 1945년 12월 설립되었다. 설립목적은 국제통화문제에 관한 협력, 국제무역 의 확대와 세계경제의 균형적 성장,\n",
      "외환의 안정 촉진, 다자간 결제제도 확립, 회원국의  국제수지 불균형 완화 등으로 되어 있다. 이에 따라 회원국의 환율정책 및\n",
      "외환...\n",
      "Score:  0.542\n",
      "\n",
      "Node ID: c1498afa-01c1-4d65-b7d1-a50e4abc125b\n",
      "Text: 2 경제금융용어 700선 흑자를 냈다면 그 가정은 벌어들인 수입 일부만을 사용했다는 것을 의미하며, 적자를  냈다면\n",
      "수입 외에 빚을 추가로 얻어 사용한 것이라고 보아야 한다. 우리나라는 통계청에 서 가계의 수입과 지출을 조사하여 국민의\n",
      "소득수준 및 생활실태를 파악하기 위해  표본으로 선정된 가계에 가계부를 나누어 주고 한 달간의 소득과 지출을 기록하도록  한\n",
      "다음 이를 토대로 가계수지 통계를 작성하여 발표하고 있다. 가계부의 소득항목에는  근로소득･사업소득･재산소득･이전소득 항목이\n",
      "있고, 비용항목에는 식료품비･주거비･ 수도광열비･보건의료비･교육비 항목이 있다 .  연관검색어 : 경상수지, 재정수지\n",
      "가계순저축률 일...\n",
      "Score:  0.411\n",
      "\n",
      "Node ID: 11f001b4-0d6b-40dc-9f83-b46f5917659d\n",
      "Text: 9 ㄱ  결제하는 중요시스템으로서 결제시점 관리와 결제리스크 감축의 필요성이 높아 주요국의  거액결제시스템은 대부분\n",
      "신용리스크를 제거할 수 있는 실시간총액결제방식을 채택하고  있으며 운영도 중앙은행이 직접 맡는 경우가 많다. 우리나라의\n",
      "한은금융망(BOK-Wire+),  미국 연준의 Fedwire, 유럽중앙은행(ECB)의 TARGET2 등이 여기에 해당된다 .\n",
      "연관검색어 : 소액결제시스템, 지급결제시스템, 총액결제시스템 거액익스포저 규제 은행의 특정 차주 등에 대한 신용공여가 과대한\n",
      "경우 해당 거래상대방의 채무불이행  등의 발생시 해당 은행의 자본건전성을 심하게 훼손할 가능성(편중리스크)이 있다 .\n",
      "바젤Ⅱ에서는 ...\n",
      "Score:  0.411\n",
      "\n",
      "Node ID: 44242c76-6046-4edd-963c-912606732049\n",
      "Text: 76 경제금융용어 700선 도 발생하지만, 해당 행동에 대한 사회적 평가 또는 해당 행동을 한 주체의 사회적\n",
      "소외의 결과로도 발생할 수 있다. 어떤 사람이 실수나 불가피한 상황에 의해 사회적으로  바람직하지 못한 행위를 한 번 저지르고\n",
      "이로 인해 나쁜 사람으로 낙인 찍히면 그  사람에 대한 부정적 인식이 형성되고 이 인식은 쉽게 사라지지 않는다. 이로 인해\n",
      "추후  어떤 상황이 발생했을 때 해당 사람에 대한 부정적 사회인식 때문에 유독 그 사람에게  상황이 부정적으로 전개되어 실제로\n",
      "일탈 또는 범죄행위가 저질러지는 현상을 낳는바,  이를 낙인효과라고 한다. 경제 분야에서도 이러한 현상이 발생한다. 예를\n",
      "들어, 과거...\n",
      "Score:  0.411\n",
      "\n",
      "Node ID: f6596d07-1552-4510-9085-8cca100bc3f8\n",
      "Text: 60 경제금융용어 700선 당국의 주요 관심사가 되었다. 2007년 미국의 서브프라임 모기지 사태와 2008년 9\n",
      "월  리먼브라더스 파산으로 촉발된 글로벌 금융위기는 세계적인 금융불안과 실물경제 침체 라는 전례가 드문 충격을 가져오면서 각국\n",
      "정책당국과 시장참가자에게 금융안정의 중요 성과 정책수단의 개발 필요성을 재인식하는 계기가 되었다. 2011년 9월\n",
      "｢한국은행법｣  개정으로 한국은행은 금융안정 책무를 명시적으로 부여받았다 .  연관검색어 : 시스템 리스크\n",
      "금융안정위원회(FSB) 기존 금융안정포럼(FSF)의 국제금융시장 안정 기능을 보다 강화하기 위하여 동 포럼의  참여 대상,\n",
      "책무, 권한 등을 확대 ･개편하여 ...\n",
      "Score:  0.409\n",
      "\n",
      "Node ID: 8e6d303a-f227-473c-8bca-2a0eb5627995\n",
      "Text: 24 경제금융용어 700선 력의 저하를 초래할 수 있는 요인이 현재화되어 채권회수에 상당한 위험이 발생한  여신\n",
      "또는 3개월 이상 연체하거나 부도가 발생한 차주의 여신 중 담보처분에 의한  회수예상가액 해당 여신을 말한다. 현행 ｢은행업\n",
      "감독규정｣에서는 고정분류여신에 대한  대손충당금은 기업 및 가계 모두 20% 이상 적용하여 적립하도록 규정하고 있다. 예를\n",
      "들어, 기업 여신액 100억원 중 회수가능금액이 80억원일 경우 최소 16억원 이상 대손충당 금으로 적립하여야 한다 .\n",
      "연관검색어 : 자산건전성 분류 고정이하여신비율 은행은 보유하고 있는 여신을 자산건전성에 따라 5단계로 분류하여 관리하고 있다.\n",
      "즉 자...\n",
      "Score:  0.409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rufrhk 결과 출력\n",
    "for node_score_obj in combined_score:\n",
    "    print(node_score_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 커스텀 검색기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step5. Rerank 적용한 BM25+Custom Retriever 클래스 생성 \n",
    "# Base query engine import\n",
    "from llama_index.core.base.base_retriever import BaseRetriever\n",
    "from llama_index.core import QueryBundle\n",
    "\n",
    "# BM25 -> 크로스인코더 Rerank를 수행하는 Custom Retriever 구현\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    def __init__(self, base_retriever, reranker:CrossEncoder):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        :param base_retriever: 1st ranking \n",
    "        :param reranker: Cross Encoder 기반 리랭크 검색기\n",
    "        \"\"\"\n",
    "        self.base_retriever = base_retriever \n",
    "        self.reranker = reranker\n",
    "    # retrieve 함수 coustomizing\n",
    "    def _retrieve(self, query_input:str)->list[Document]:\n",
    "        # 1) QueryBundle이면 내부 query_str를 꺼냄\n",
    "        if isinstance(query_input, QueryBundle): query = query_input.query_str\n",
    "        else: query = query_input  # 그냥 문자열 혹은 그 외 케이스\n",
    "            \n",
    "        # 1) Base Retriever - 혼합검색\n",
    "        try: initial_docs = self.base_retriever.retrieve(query)\n",
    "        except: print('### Base Retrieve Error')\n",
    "        \n",
    "        # 2) rerank\n",
    "        reranked_docs_with_score = self.reranker.rerank(query, initial_docs)\n",
    "        \n",
    "        # 3) (Document, score) 튜플에서 Document만 추출\n",
    "        #    Document + score가 모두 필요하다면 QueryEngine 쪽 custom 로직 필요\n",
    "        final_docs = [doc_score_tuple[0] for doc_score_tuple in reranked_docs_with_score]\n",
    "        return final_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 혼합검색 + 크로스 인코더 리랭크 검색기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step6-1. Hybrid search\n",
    "# hybrid retriever \n",
    "hybrid_retriever = HybridSearch(bm25_retriever=bm25_retriever,\n",
    "                                semantic_retriever=semantic_retriever,\n",
    "                                bm25_weight=0.5,\n",
    "                                semantic_weight=0.5)\n",
    "\n",
    "### Step6-2. Cross Encoder Rerank\n",
    "path = r\"./reranker_model/bge-reranker-v2-m3\"\n",
    "cross_encoder = CrossEncoder(path) # 크로스 인코더 객체 생성\n",
    "cross_encoder_rerank = CrossEncoderReranker(top_k=2, cross_encoder=cross_encoder)\n",
    "\n",
    "### Step6-3. 커스텀 검색기 작성\n",
    "custom_retriever = CustomRetriever(base_retriever=hybrid_retriever,\n",
    "                                   reranker=cross_encoder_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CustomRetriever 내부에서 _retrieve()메서드에 대한 내용을 작성했지만\n",
    "실제 호출시에는 retrieve()를 사용함.\n",
    "라마인덱스 BaseRetirever의 retrieve() 메서드 내부에서 _retrieve()를 호출하게끔 되어있음.\n",
    "따라서, 사용자는 retrieve()를 사용하면 원하는 결과를 얻을 수 잇음.\n",
    "(_retrieve()를 호출해도 결과는 같지만 호환성 문제를 방지하기 위함)\n",
    "'''\n",
    "query='가계부실위험지수에 대해 알려주세요'\n",
    "result = custom_retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 83b53498-dba3-4f12-8dba-7e3d8e9f43b6\n",
      "Text: 1 ㄱ  ㄱ 가계부실위험지수(HDRI) 가구의 소득 흐름은 물론 금융 및 실물 자산까지 종합적으로 고려하여\n",
      "가계부채의  부실위험을 평가하는 지표로, 가계의 채무상환능력을 소득 측면에서 평가하는 원리금상 환비율(DSR; Debt\n",
      "Service Ratio)과 자산 측면에서 평가하는 부채/자산비율(DTA; Debt  To Asset Ratio)을 결합하여\n",
      "산출한 지수이다. 가계부실위험지수는 가구의 DSR과 DTA가  각각 40%, 100%일 때 100의 값을 갖도록 설정되어\n",
      "있으며, 동 지수가 100을 초과하는  가구를 ‘위험가구’로 분류한다. 위험가구는 소득 및 자산 측면에서 모두 취약한\n",
      "‘고위험가구’,  자산 측면에...\n",
      "Score:  0.410\n",
      " <class 'llama_index.core.schema.NodeWithScore'>\n",
      "Node ID: f6596d07-1552-4510-9085-8cca100bc3f8\n",
      "Text: 60 경제금융용어 700선 당국의 주요 관심사가 되었다. 2007년 미국의 서브프라임 모기지 사태와 2008년 9\n",
      "월  리먼브라더스 파산으로 촉발된 글로벌 금융위기는 세계적인 금융불안과 실물경제 침체 라는 전례가 드문 충격을 가져오면서 각국\n",
      "정책당국과 시장참가자에게 금융안정의 중요 성과 정책수단의 개발 필요성을 재인식하는 계기가 되었다. 2011년 9월\n",
      "｢한국은행법｣  개정으로 한국은행은 금융안정 책무를 명시적으로 부여받았다 .  연관검색어 : 시스템 리스크\n",
      "금융안정위원회(FSB) 기존 금융안정포럼(FSF)의 국제금융시장 안정 기능을 보다 강화하기 위하여 동 포럼의  참여 대상,\n",
      "책무, 권한 등을 확대 ･개편하여 ...\n",
      "Score:  0.409\n",
      " <class 'llama_index.core.schema.NodeWithScore'>\n"
     ]
    }
   ],
   "source": [
    "for one in result:\n",
    "    print(one, type(one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 쿼리 엔진 및 응답 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step7. query engine 생성 및 응답 확인\n",
    "# Custom Retriever를 사용하기 위해선 RetrieverQueryEngine을 사용해야 함\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "query_engine = RetrieverQueryEngine(retriever=custom_retriever,) # query engine 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : 가계부실위험지수에 대해 알려주세요\n"
     ]
    }
   ],
   "source": [
    "query='가계부실위험지수에 대해 알려주세요'\n",
    "print(f\"Query : {query}\")\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가계부실위험지수는 가구의 소득 흐름과 금융 및 실물 자산을 종합적으로 고려하여 가계부채의 부실위험을 평가하는 지표입니다. 이 지수는 소득 측면에서의 채무상환능력을 나타내는 원리금상환비율(DSR)과 자산 측면에서의 부채/자산비율(DTA)을 결합하여 산출됩니다. 가계부실위험지수는 가구의 DSR과 DTA가 각각 40%, 100%일 때 100의 값을 갖도록 설정되어 있으며, 이 지수가 100을 초과하는 가구는 '위험가구'로 분류됩니다. 위험가구는 소득 및 자산 측면에서 모두 취약한 '고위험가구', 자산 측면에서 취약한 '고DTA가구', 소득 측면에서 취약한 '고DSR가구'로 구분할 수 있습니다. 다만, 위험 및 고위험 가구는 채무상환능력의 취약성을 평가하기 위한 것이며, 이들이 당장 채무상환 불이행 상태에 직면한 것을 의미하지는 않습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 83b53498-dba3-4f12-8dba-7e3d8e9f43b6\n",
      "Text: 1 ㄱ  ㄱ 가계부실위험지수(HDRI) 가구의 소득 흐름은 물론 금융 및 실물 자산까지 종합적으로 고려하여\n",
      "가계부채의  부실위험을 평가하는 지표로, 가계의 채무상환능력을 소득 측면에서 평가하는 원리금상 환비율(DSR; Debt\n",
      "Service Ratio)과 자산 측면에서 평가하는 부채/자산비율(DTA; Debt  To Asset Ratio)을 결합하여\n",
      "산출한 지수이다. 가계부실위험지수는 가구의 DSR과 DTA가  각각 40%, 100%일 때 100의 값을 갖도록 설정되어\n",
      "있으며, 동 지수가 100을 초과하는  가구를 ‘위험가구’로 분류한다. 위험가구는 소득 및 자산 측면에서 모두 취약한\n",
      "‘고위험가구’,  자산 측면에...\n",
      "Score:  0.410\n",
      "\n",
      "Node ID: f6596d07-1552-4510-9085-8cca100bc3f8\n",
      "Text: 60 경제금융용어 700선 당국의 주요 관심사가 되었다. 2007년 미국의 서브프라임 모기지 사태와 2008년 9\n",
      "월  리먼브라더스 파산으로 촉발된 글로벌 금융위기는 세계적인 금융불안과 실물경제 침체 라는 전례가 드문 충격을 가져오면서 각국\n",
      "정책당국과 시장참가자에게 금융안정의 중요 성과 정책수단의 개발 필요성을 재인식하는 계기가 되었다. 2011년 9월\n",
      "｢한국은행법｣  개정으로 한국은행은 금융안정 책무를 명시적으로 부여받았다 .  연관검색어 : 시스템 리스크\n",
      "금융안정위원회(FSB) 기존 금융안정포럼(FSF)의 국제금융시장 안정 기능을 보다 강화하기 위하여 동 포럼의  참여 대상,\n",
      "책무, 권한 등을 확대 ･개편하여 ...\n",
      "Score:  0.409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v in response.source_nodes:\n",
    "    print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
