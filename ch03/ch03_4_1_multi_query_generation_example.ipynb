{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Multi Query Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step1. API KEY 설정\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import Prompt\n",
    "# 쿼리 변환용 프롬프트 설정\n",
    "decompose_prompt = Prompt(\n",
    "    \"\"\"\n",
    "    다음 [Original Query]와 관련있는 여러개의 쿼리를 3가지로 변환시켜주세요.\n",
    "    출력 포맷은 아래와 같은 형태를 지켜주세요.\n",
    "    \n",
    "    Original Query: {query_str}\n",
    "    Sub-Queries:\n",
    "    1.\n",
    "    2.\n",
    "    3.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecomposeQueryTransform 초기화\n",
    "from llama_index.core.indices.query.query_transform.base import DecomposeQueryTransform\n",
    "decompose = DecomposeQueryTransform(decompose_query_prompt=decompose_prompt, \n",
    "                                    llm=Settings.llm,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;33m> Current query: RAG에 대해 알려주세요.\n",
      "\u001b[0m\u001b[1;3;38;5;200m> New query: Original Query: RAG에 대해 알려주세요.  \n",
      "Sub-Queries:  \n",
      "1. RAG의 주요 기능은 무엇인가요?  \n",
      "2. RAG의 장점과 단점은 무엇인가요?  \n",
      "3. RAG를 사용하는 사례가 있나요?  \n",
      "\u001b[0mOriginal Query: RAG에 대해 알려주세요.  \n",
      "Sub-Queries:  \n",
      "1. RAG의 주요 기능은 무엇인가요?  \n",
      "2. RAG의 장점과 단점은 무엇인가요?  \n",
      "3. RAG를 사용하는 사례가 있나요?  \n"
     ]
    }
   ],
   "source": [
    "query = \"RAG에 대해 알려주세요.\" # 입력 쿼리\n",
    "query_bundle = decompose.run(query) # 쿼리 변환 수행\n",
    "print(query_bundle.query_str) # 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query = query_bundle.query_str.split('\\n')[2:]\n",
    "input_query = query_bundle.query_str.split('\\n')[0]\n",
    "sub_query_join = '\\n'.join(sub_query) # sub query 만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "final_prompt_template = PromptTemplate(\n",
    "                        template = \"\"\"아래 [Original-Query]와 [Sub-Queries]에 대한 내용을 모두 종합 및 요약해서 알려주세요.\n",
    "                        \\n{input_query}\n",
    "                        \\n[Sub-Queires]\n",
    "                        \\n{sub_query}\n",
    "                        \"\"\",\n",
    "                        template_vars=\"input_query, sub_query\"\n",
    "                    )\n",
    "final_prompt = final_prompt_template.format(input_query=input_query,\n",
    "                                            sub_query=sub_query_join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 [Original-Query]와 [Sub-Queries]에 대한 내용을 모두 종합 및 요약해서 알려주세요.\n",
      "                        \n",
      "Original Query: RAG에 대해 알려주세요.  \n",
      "                        \n",
      "[Sub-Queires]\n",
      "                        \n",
      "1. RAG의 주요 기능은 무엇인가요?  \n",
      "2. RAG의 장점과 단점은 무엇인가요?  \n",
      "3. RAG를 사용하는 사례가 있나요?  \n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o\", temperature=0.5, max_toknes=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Query만 사용할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG는 \"Retrieval-Augmented Generation\"의 약자로, 자연어 처리 분야에서 정보를 생성하는 모델에 외부 지식을 결합하여 더 정확하고 풍부한 응답을 생성하는 기술을 의미합니다. RAG는 주로 두 가지 주요 구성 요소로 이루어져 있습니다: 정보 검색기(retriever)와 생성기(generator).\n",
      "\n",
      "1. **정보 검색기(Retriever)**: 이 단계에서는 주어진 질문이나 문맥에 맞는 관련 정보를 대규모 데이터베이스나 문서 집합에서 검색합니다. 이를 통해 모델은 외부 지식을 활용하여 더 정확한 답변을 생성할 수 있습니다.\n",
      "\n",
      "2. **생성기(Generator)**: 검색기가 제공한 정보를 바탕으로 자연스러운 언어로 응답을 생성합니다. 이 단계는 일반적으로 Transformer 기반의 언어 모델을 사용하여 수행됩니다.\n",
      "\n",
      "RAG는 특히 대규모 언어 모델이 훈련된 데이터에 포함되지 않은 정보에 접근해야 할 때 유용합니다. 예를 들어, 최신 뉴스나 특정 도메인에 대한 전문 지식이 필요한 경우에 효과적일 수 있습니다. 이러한 방식은 정적 모델보다 더 유연하고 업데이트하기 쉬운 시스템을 구축하는 데 도움이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "## Original qeury response\n",
    "response_original = llm.complete(query) # original query에 대한 답변\n",
    "print(response_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Query를 사용할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi query response\n",
    "response = llm.complete(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG(Recursively Augmented Generation)는 자연어 처리(NLP) 분야에서 정보를 검색하고 생성하는 데 사용되는 기술입니다. 주로 대규모 언어 모델과 정보 검색 시스템을 결합하여 질문에 대한 정확하고 풍부한 답변을 생성하는 데 활용됩니다.\n",
      "\n",
      "1. **RAG의 주요 기능:**\n",
      "   - **정보 검색:** RAG는 대규모 데이터베이스나 문서 집합에서 관련 정보를 검색하는 기능을 가지고 있습니다. 이를 통해 질문에 대한 배경 정보를 수집합니다.\n",
      "   - **텍스트 생성:** 검색된 정보를 기반으로 자연어 텍스트를 생성합니다. 이는 대화형 AI나 질문 답변 시스템에서 사용될 수 있습니다.\n",
      "   - **정보 통합:** 검색된 정보와 생성된 텍스트를 통합하여 사용자에게 더 풍부한 답변을 제공합니다.\n",
      "\n",
      "2. **RAG의 장점과 단점:**\n",
      "   - **장점:**\n",
      "     - **정확성 향상:** 검색된 정보에 기반하여 답변을 생성하기 때문에 일반적인 언어 모델보다 더 정확한 답변을 제공할 수 있습니다.\n",
      "     - **정보 다양성:** 다양한 출처에서 정보를 수집하여 더 다양한 관점을 제공할 수 있습니다.\n",
      "   - **단점:**\n",
      "     - **복잡성:** 시스템의 복잡성이 증가하여 구현 및 유지보수가 어려울 수 있습니다.\n",
      "     - **실시간성 문제:** 대규모 데이터베이스에서 정보를 검색하고 처리하는 데 시간이 걸릴 수 있어 실시간 응답이 어려울 수 있습니다.\n",
      "\n",
      "3. **RAG를 사용하는 사례:**\n",
      "   - **고객 지원:** 고객의 질문에 대한 정확한 답변을 제공하기 위해 RAG를 활용하는 사례가 있습니다. 이를 통해 고객 만족도를 높일 수 있습니다.\n",
      "   - **의료 정보 제공:** 의료 분야에서 환자나 의료진에게 정확한 정보를 제공하기 위해 RAG를 사용할 수 있습니다.\n",
      "   - **학술 연구:** 연구자들이 방대한 양의 학술 문헌에서 필요한 정보를 빠르게 검색하고 요약하는 데 도움을 줄 수 있습니다.\n",
      "\n",
      "RAG는 정보 검색과 생성의 장점을 결합하여 다양한 분야에서 활용될 수 있으며, 특히 정확성과 정보의 풍부함이 중요한 응용 분야에서 유용합니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
