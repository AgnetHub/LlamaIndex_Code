{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RAG 관련 pdf 예제 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "# 문서 로드 및 인덱스 생성\n",
    "documents = SimpleDirectoryReader(input_files=[\"../data/pdf_example.pdf\"]).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 가장 기본적인 쿼리 엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG는 'Retrieval-Augmented Generation'의 줄임말로, AI가 질문에 답할 때 자신이 가진 지식에만 의존하지 않고, 필요한 정보를 찾아보고 답변하는 방식을 채택한 기술입니다. 이는 마치 학생이 도서관에서 책을 찾아보고 답을 작성하는 것과 유사한 원리로 작동합니다.\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 엔진 생성\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# 쿼리 실행\n",
    "query = \"RAG에 대해서 설명해줘\"\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# 응답 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. as_query_engine() 주요 파라미터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG의 장점은 다음과 같습니다:  \n",
      "- 정확한 정보 제공: 학생이 교과서를 참고하여 답변하는 것처럼, RAG는 신뢰할 수 있는 정보를 바탕으로 답변합니다.  \n",
      "- 최신 정보 활용: RAG는 새로운 정보를 추가할 수 있어서 항상 최신 정보를 활용하여 답변할 수 있습니다.  \n",
      "- 출처 제시: RAG는 어디서 정보를 찾았는지 알려줄 수 있어서 답변을 신뢰할 수 있습니다."
     ]
    }
   ],
   "source": [
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    # 기본적인 설정\n",
    "    similarity_top_k=3,                # 상위 3개 문서 사용\n",
    "    response_mode=\"tree_summarize\",    # 트리 구조로 요약\n",
    "    streaming=True,                    # 스트리밍 응답 활성화\n",
    "    # 유사도 0.7 이상만 선택 (후처리)\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)]\n",
    "    )\n",
    "\n",
    "query = \"RAG의 장점에 대해서 설명해줘\"\n",
    "\n",
    "# 스트리밍 쿼리 실행\n",
    "streaming_response = query_engine.query(query)\n",
    "streaming_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ========== 응답 모드: tree_summarize ==========\n",
      "RAG는 'Retrieval-Augmented Generation'의 줄임말로, AI가 질문에 답할 때 자신이 가진 지식에만 의존하지 않고, 필요한 정보를 찾아보고 답변하는 방식을 채택한 기술입니다. 이는 마치 도서관에서 공부하는 학생이 필요한 정보를 찾아보고 답하는 것과 유사한 작동 방식을 가지고 있습니다. RAG는 정확한 정보를 제공하고 최신 정보를 활용할 수 있으며, 출처를 제시하여 신뢰할 수 있는 답변을 제공하는 장점을 가지고 있습니다.\n",
      "\n",
      " ========== 응답 모드: refine ==========\n",
      "RAG는 'Retrieval-Augmented Generation'의 줄임말로, AI가 질문에 답할 때 자신이 가진 지식에만 의존하지 않고, 필요한 정보를 찾아보고 답변하는 방식입니다. 이는 마치 학생이 도서관에서 책을 찾아보고 그 내용을 바탕으로 답을 작성하는 것과 유사합니다.\n",
      "\n",
      " ========== 응답 모드: compact ==========\n",
      "RAG는 'Retrieval-Augmented Generation'의 줄임말로, AI가 질문에 답할 때 자신이 가진 지식에만 의존하지 않고, 필요한 정보를 찾아보고 답변하는 방식을 채택한 기술입니다. 이는 AI가 정보를 검색하여 가져오고 그것을 기반으로 답변을 생성하는 방식으로 작동합니다. RAG의 장점으로는 정확한 정보 제공, 최신 정보 활용, 그리고 출처 제시가 있습니다. 이러한 기술은 학교 도우미 AI, 도서관 안내 로봇, 그리고 고객 서비스 챗봇 등 다양한 분야에서 활용될 수 있습니다. RAG는 일반 LLM과의 차이점으로, 암기에만 의존하지 않고 필요할 때마다 정보를 찾아 정확한 답변을 제공하는 점을 강조합니다. 이로써 RAG는 AI가 똑똑하고 정확하게 답변할 수 있도록 도와주는 중요한 기술로 손꼽힙니다.\n"
     ]
    }
   ],
   "source": [
    "# 2.테스트할 응답 모드 리스트\n",
    "response_modes = [\"tree_summarize\", \"refine\", \"compact\"]\n",
    "\n",
    "\n",
    "# 3.동일한 질문에 대해 응답 모드별로 실행\n",
    "question = \"RAG에 대해서 설명해줘\"\n",
    "\n",
    "for mode in response_modes:\n",
    "    print(f\"\\n ========== 응답 모드: {mode} ==========\")\n",
    "    \n",
    "    # Query Engine 생성 및 실행\n",
    "    query_engine = index.as_query_engine(response_mode=mode)\n",
    "    response = query_engine.query(question)\n",
    "    \n",
    "    # 응답 출력\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
